{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb996028-8ad1-44de-8441-1b65a17ea7e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Propensity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b715a6c5-51fe-404f-9f1a-5f06857e98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17b645-dcac-43c9-bb2e-3dc8d69b3d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pkl.load(open('../data/data.pkl', 'rb'))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6589aa-f3d3-49e8-88de-21ccb3a567a7",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808672ab-43f6-4761-9a5c-478b8ed95f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aucs, test_aucs = [], []\n",
    "models = []\n",
    "rocs = []\n",
    "for i, (train_index, test_index) in enumerate(KFold(5).split(data)):\n",
    "    train = data.iloc[train_index, :]\n",
    "    test = data.iloc[test_index, :]\n",
    "    x_train = train[train.columns[~train.columns.isin(['T','Y'])]]\n",
    "    x_test = test[test.columns[~test.columns.isin(['T','Y'])]]\n",
    "    t_train = train['T'].values\n",
    "    t_test = test['T'].values\n",
    "    \n",
    "    # Logistic regression\n",
    "    log_reg = LogisticRegression(max_iter=10000).fit(x_train, t_train)\n",
    "    probs_train = log_reg.predict_proba(x_train)[:,1]\n",
    "    probs_test = log_reg.predict_proba(x_test)[:, 1]\n",
    "    test_fpr, test_tpr, _ = metrics.roc_curve(test['T'],  probs_test)\n",
    "    test_auc = metrics.roc_auc_score(test['T'],  probs_test)\n",
    "    train_fpr, train_tpr, _ = metrics.roc_curve(train['T'],  probs_train)\n",
    "    train_auc = metrics.roc_auc_score(train['T'],  probs_train)\n",
    "    models.append({'name': 'LR', 'epoch':i, 'train auc':train_auc, 'test auc':test_auc})\n",
    "    rocs.append({'name': 'LR', 'epoch':i, 'test_fpr':test_fpr, 'test_tpr':test_tpr, 'train_fpr':train_fpr, 'train_tpr':train_tpr})\n",
    "    \n",
    "    # Random forest classifier\n",
    "    rndfrst = RandomForestClassifier(max_depth=5, random_state=0).fit(x_train, t_train)\n",
    "    probs_train = log_reg.predict(x_train)\n",
    "    probs_test = log_reg.predict(x_test)\n",
    "    test_fpr, test_tpr, _ = metrics.roc_curve(test['T'],  probs_test)\n",
    "    test_auc = metrics.roc_auc_score(test['T'],  probs_test)\n",
    "    train_fpr, train_tpr, _ = metrics.roc_curve(train['T'],  probs_train)\n",
    "    train_auc = metrics.roc_auc_score(train['T'],  probs_train)\n",
    "    models.append({'name': 'RF', 'epoch':i, 'train auc':train_auc, 'test auc':test_auc})\n",
    "    rocs.append({'name': 'RF', 'epoch':i, 'test_fpr':test_fpr, 'test_tpr':test_tpr, 'train_fpr':train_fpr, 'train_tpr':train_tpr})\n",
    "    \n",
    "    # AdaBoost\n",
    "    rndfrst = AdaBoostClassifier(n_estimators=100, random_state=0).fit(x_train, t_train)\n",
    "    probs_train = log_reg.predict(x_train)\n",
    "    probs_test = log_reg.predict(x_test)\n",
    "    test_fpr, test_tpr, _ = metrics.roc_curve(test['T'],  probs_test)\n",
    "    test_auc = metrics.roc_auc_score(test['T'],  probs_test)\n",
    "    train_fpr, train_tpr, _ = metrics.roc_curve(train['T'],  probs_train)\n",
    "    train_auc = metrics.roc_auc_score(train['T'],  probs_train)\n",
    "    models.append({'name': 'AB', 'epoch':i, 'train auc':train_auc, 'test auc':test_auc})\n",
    "    rocs.append({'name': 'AB', 'epoch':i, 'test_fpr':test_fpr, 'test_tpr':test_tpr, 'train_fpr':train_fpr, 'train_tpr':train_tpr})\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4744e-7ae2-46d6-8478-8b181d9144a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(models)\n",
    "models[['name', 'train auc', 'test auc']].groupby('name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802fade-e693-41f6-aad3-0ded399ee06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs = pd.DataFrame(rocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a2776-625e-41ff-b736-1fb8189d04c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(20,6))\n",
    "epoch = 0\n",
    "for i, name in enumerate(['LR', 'RF', 'AB']):\n",
    "    ax = axes[i]\n",
    "    alg_epoch = rocs[(rocs['epoch']==epoch)&(rocs['name']==name)]\n",
    "    test_fpr, test_tpr = alg_epoch['test_fpr'].item(), alg_epoch['test_tpr'].item()\n",
    "    train_fpr, train_tpr = alg_epoch['train_fpr'].item(), alg_epoch['train_tpr'].item()\n",
    "    \n",
    "    ax.plot(test_fpr, test_tpr, label=f'Test (AUC={round(test_auc,2)})')\n",
    "    ax.plot(train_fpr, train_tpr, label=f'Train (AUC={round(train_auc,2)})')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"ROC curve for {name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d63f39-b062-4c1c-b452-bada2614d5af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bfa05-7704-4189-ac0b-59c59af4c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_props(df):\n",
    "    x = df[df.columns[~df.columns.isin(['T','Y'])]]\n",
    "    t = df['T'].values\n",
    "    log_reg = LogisticRegression(max_iter=10000).fit(x, t)\n",
    "    probs = \n",
    "    df['propensity'] = log_reg.predict_proba(x)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977f20e-cdd8-44c4-913f-32060e298df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = calc_props(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f0a8f7-ba48-4cba-87cb-e5bc3c13899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "data[data['T']==1].propensity.hist(bins=30, ax=ax, alpha=0.6, density=True, label='T = True')\n",
    "data[data['T']==0].propensity.hist(bins=30, ax=ax, alpha=0.6, density=True, label='T = False')\n",
    "plt.title(\"Propensity scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bead663-b489-4a27-b8ee-726e396765b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "if save:\n",
    "    pkl.dump(data, open(\"../data/data_p.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
